{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d634c8bf-7b3b-4000-a802-f470a31190e5",
   "metadata": {},
   "source": [
    "<h1 style=\"color:Green; font-size:3em;\">Import and Check RAVDESS Dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec7a6ac-acaf-4c28-a2c1-5f4b2ec61eb9",
   "metadata": {},
   "source": [
    "<h2 style=\"color:purple; font-size:2em;\">Dataset Info</h2>\n",
    "<p style=\"font-size:15px;\"\">-Name: RAVDESS – Ryerson Audio-Visual Database of Emotional Speech and Song<br>\n",
    "-Subset: Speech-only (No song, no video)<br>\n",
    "-Total samples: 1440 audio files (60 per actor × 24 actors)<br>\n",
    "-Emotions: 8 (neutral, calm, happy, sad, angry, fearful, disgust, surprised)<br>\n",
    "-File format: .wav (mono, 48kHz)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a065ce99-d1ec-424d-9867-66f6589e426b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:purple; font-size:2em;\">Import Required Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97bb1002-b864-4567-b484-e319ea40a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import librosa\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from glob import glob \n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a0e84-9aed-4819-95f0-19f8a6506f7e",
   "metadata": {},
   "source": [
    "<h2 style=\"color:purple;\">Set Data Directory</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e987dd2-bbbe-4161-9761-d48b34699974",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "OUTPUT_PATH = \"./processed_data\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd723630-7fb1-4f5f-a3b6-aacd27352ec6",
   "metadata": {},
   "source": [
    "<h2 style=\"color:purple;\">Define Emotion Code Mapping</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9037d24f-9ac7-4692-8c9c-cf295e11cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35021f89-642b-4f1d-9060-3b83a5f032e2",
   "metadata": {},
   "source": [
    "<h2 style=\"color:purple;\">Emotion Categories for feature enhancement</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88711e5f-46ef-4fb9-9fcf-470ac6597c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_arousal = ['angry', 'fearful', 'happy', 'surprised']\n",
    "low_arousal = ['calm', 'sad', 'neutral', 'disgust']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d18e6b-3db8-4112-a959-c783c6f7a624",
   "metadata": {},
   "source": [
    "<h2 style=\"color:purple;\">Feature Extraction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43ba54e-d3ea-46c8-86fc-0deff295c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(y, sr, emotion):\n",
    "    \"\"\"Extract enhanced audio features with emotion-specific processing\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Basic features\n",
    "    features['duration'] = librosa.get_duration(y=y, sr=sr)\n",
    "    features['loudness'] = np.mean(librosa.amplitude_to_db(np.abs(y)))\n",
    "    \n",
    "    # Voice activity detection\n",
    "    intervals = librosa.effects.split(y, top_db=20)\n",
    "    active_frames = np.sum([end-start for start, end in intervals])\n",
    "    features['voice_ratio'] = active_frames / len(y)\n",
    "    \n",
    "    # Spectral features with temporal statistics\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
    "    \n",
    "    for name, feature in [('centroid', spectral_centroid),\n",
    "                         ('rolloff', spectral_rolloff),\n",
    "                         ('bandwidth', spectral_bandwidth)]:\n",
    "        features[f'{name}_mean'] = np.mean(feature)\n",
    "        features[f'{name}_std'] = np.std(feature)\n",
    "        features[f'{name}_skew'] = skew(feature)\n",
    "        features[f'{name}_kurt'] = kurtosis(feature)\n",
    "    \n",
    "    # MFCCs with deltas\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    \n",
    "    for i in range(13):\n",
    "        features[f'mfcc_{i+1}'] = np.mean(mfcc[i])\n",
    "        features[f'mfcc_{i+1}_delta'] = np.mean(mfcc_delta[i])\n",
    "    \n",
    "    # Chroma and advanced features\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    \n",
    "    for i in range(12):\n",
    "        features[f'chroma_{i+1}'] = np.mean(chroma[i])\n",
    "    for i in range(7):\n",
    "        features[f'contrast_{i+1}'] = np.mean(contrast[i])\n",
    "    for i in range(6):\n",
    "        features[f'tonnetz_{i+1}'] = np.mean(tonnetz[i])\n",
    "    \n",
    "    # Emotion-specific features\n",
    "    if emotion in high_arousal:\n",
    "        harmonic, percussive = librosa.effects.hpss(y)\n",
    "        features['energy_ratio'] = np.sum(percussive**2) / (np.sum(harmonic**2) + 1e-6)\n",
    "    elif emotion in low_arousal:\n",
    "        features['silence_ratio'] = 1 - features['voice_ratio']\n",
    "    \n",
    "    # Pitch features\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    pitch_mean = np.mean(pitches[magnitudes > np.median(magnitudes)])\n",
    "    features['pitch_mean'] = pitch_mean if not np.isnan(pitch_mean) else 0\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba0b8d5-27c8-4cee-81da-a89603c2550b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:purple;\">Audio processing function with augmentation\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db944818-2af0-4f62-933b-2c0bf8c0ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "    try:\n",
    "        # Parse filename\n",
    "        filename = os.path.basename(file_path)\n",
    "        parts = filename.split('-')\n",
    "        actor_num = int(parts[6].split('.')[0])\n",
    "        emotion_code = parts[2]\n",
    "        emotion = emotion_map[emotion_code]\n",
    "\n",
    "        # Load and preprocess audio\n",
    "        y, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "        y = librosa.effects.preemphasis(y)\n",
    "        y = librosa.effects.trim(y, top_db=25)[0]\n",
    "        \n",
    "        # RMS normalization\n",
    "        rms = np.sqrt(np.mean(y**2))\n",
    "        y = y / (rms + 1e-6)\n",
    "        \n",
    "        # Base features\n",
    "        features = {\n",
    "            'filename': filename,\n",
    "            'actor': actor_num,\n",
    "            'gender': 'male' if actor_num % 2 == 0 else 'female',\n",
    "            'emotion': emotion,\n",
    "            'emotion_code': emotion_code\n",
    "        }\n",
    "        features.update(extract_features(y, sr, emotion))\n",
    "        \n",
    "        # Data augmentation\n",
    "        augmented_features = []\n",
    "        \n",
    "        # Time stretching\n",
    "        y_stretch = librosa.effects.time_stretch(y, rate=0.8)\n",
    "        stretch_feats = extract_features(y_stretch, sr, emotion)\n",
    "        stretch_feats.update({\n",
    "            'filename': filename + '_stretch',\n",
    "            'actor': actor_num,\n",
    "            'gender': 'male' if actor_num % 2 == 0 else 'female',\n",
    "            'emotion': emotion,\n",
    "            'emotion_code': emotion_code\n",
    "        })\n",
    "        augmented_features.append(stretch_feats)\n",
    "        \n",
    "        # Pitch shifting\n",
    "        y_shift = librosa.effects.pitch_shift(y, sr=sr, n_steps=2)\n",
    "        shift_feats = extract_features(y_shift, sr, emotion)\n",
    "        shift_feats.update({\n",
    "            'filename': filename + '_shift',\n",
    "            'actor': actor_num,\n",
    "            'gender': 'male' if actor_num % 2 == 0 else 'female',\n",
    "            'emotion': emotion,\n",
    "            'emotion_code': emotion_code\n",
    "        })\n",
    "        augmented_features.append(shift_feats)\n",
    "        \n",
    "        return [features] + augmented_features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622823bb-4399-4d1c-bf5d-1f1446448bcd",
   "metadata": {},
   "source": [
    "<h2 style=\"color:purple;\">Process all audio files\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84816a1e-d8e3-4121-84ee-bbbffe9f170b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding all audio files...\n",
      "Processing 1440 files with augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=408\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=510\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=416\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=376\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=470\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=424\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=400\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=500\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=440\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=456\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=488\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=384\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=480\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=432\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=448\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=368\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=460\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=352\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=336\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=420\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=328\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=410\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=320\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=464\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=312\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=390\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=288\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=360\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=496\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=504\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=344\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=430\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=296\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=370\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=472\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=392\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=490\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=450\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=304\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=380\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=272\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=340\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=280\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=350\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=256\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=232\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=290\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=248\n",
      "  warnings.warn(\n",
      "/home/sabin/myenv/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=310\n",
      "  warnings.warn(\n",
      "Processing files: 100%|███████████████████| 1440/1440 [1:55:50<00:00,  4.83s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Finding all audio files...\")\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(DATA_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            all_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"Processing {len(all_files)} files with augmentation...\")\n",
    "results = []\n",
    "for file in tqdm(all_files, desc=\"Processing files\"):\n",
    "    data = process_file(file)\n",
    "    if data:\n",
    "        results.extend(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50713db-efed-4d1c-802e-95b95bcfa9b4",
   "metadata": {},
   "source": [
    "<h3 style='color:purple'>Create Dataframe and Save</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37305b7c-49d2-492f-a100-9e5d5be9027f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>actor</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_code</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>voice_ratio</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_std</th>\n",
       "      <th>...</th>\n",
       "      <th>contrast_7</th>\n",
       "      <th>tonnetz_1</th>\n",
       "      <th>tonnetz_2</th>\n",
       "      <th>tonnetz_3</th>\n",
       "      <th>tonnetz_4</th>\n",
       "      <th>tonnetz_5</th>\n",
       "      <th>tonnetz_6</th>\n",
       "      <th>silence_ratio</th>\n",
       "      <th>pitch_mean</th>\n",
       "      <th>energy_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-01-07-01-01-02-18.wav</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>disgust</td>\n",
       "      <td>07</td>\n",
       "      <td>2.176</td>\n",
       "      <td>-17.363924</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>3103.861734</td>\n",
       "      <td>1133.595952</td>\n",
       "      <td>...</td>\n",
       "      <td>51.832581</td>\n",
       "      <td>-0.018983</td>\n",
       "      <td>-0.025689</td>\n",
       "      <td>-0.019540</td>\n",
       "      <td>0.037315</td>\n",
       "      <td>-0.004874</td>\n",
       "      <td>-0.002966</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>2245.666748</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03-01-07-01-01-02-18.wav_stretch</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>disgust</td>\n",
       "      <td>07</td>\n",
       "      <td>2.720</td>\n",
       "      <td>-16.133003</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>3117.783534</td>\n",
       "      <td>1044.945930</td>\n",
       "      <td>...</td>\n",
       "      <td>51.422385</td>\n",
       "      <td>-0.005568</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.014867</td>\n",
       "      <td>0.044577</td>\n",
       "      <td>-0.008606</td>\n",
       "      <td>-0.012778</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>2203.087402</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-01-07-01-01-02-18.wav_shift</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>disgust</td>\n",
       "      <td>07</td>\n",
       "      <td>2.176</td>\n",
       "      <td>-16.485405</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>3229.374024</td>\n",
       "      <td>1080.269650</td>\n",
       "      <td>...</td>\n",
       "      <td>53.300893</td>\n",
       "      <td>-0.029735</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>-0.051420</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>2135.273682</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03-01-05-01-02-01-18.wav</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>angry</td>\n",
       "      <td>05</td>\n",
       "      <td>1.632</td>\n",
       "      <td>-12.006447</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>3149.329740</td>\n",
       "      <td>1393.901212</td>\n",
       "      <td>...</td>\n",
       "      <td>50.715246</td>\n",
       "      <td>-0.001349</td>\n",
       "      <td>-0.016009</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>-0.020919</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.004213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2139.219238</td>\n",
       "      <td>23.973597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-01-05-01-02-01-18.wav_stretch</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>angry</td>\n",
       "      <td>05</td>\n",
       "      <td>2.040</td>\n",
       "      <td>-12.320189</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>3173.226784</td>\n",
       "      <td>1353.186854</td>\n",
       "      <td>...</td>\n",
       "      <td>50.693348</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>-0.022524</td>\n",
       "      <td>0.015145</td>\n",
       "      <td>-0.022695</td>\n",
       "      <td>-0.009523</td>\n",
       "      <td>-0.004047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2079.598633</td>\n",
       "      <td>13.721988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>03-01-07-02-02-02-21.wav_stretch</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>disgust</td>\n",
       "      <td>07</td>\n",
       "      <td>2.440</td>\n",
       "      <td>-17.121801</td>\n",
       "      <td>0.681967</td>\n",
       "      <td>3172.201855</td>\n",
       "      <td>1212.521763</td>\n",
       "      <td>...</td>\n",
       "      <td>50.792559</td>\n",
       "      <td>-0.010724</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>-0.064574</td>\n",
       "      <td>-0.008770</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.318033</td>\n",
       "      <td>2215.400879</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>03-01-07-02-02-02-21.wav_shift</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>disgust</td>\n",
       "      <td>07</td>\n",
       "      <td>1.952</td>\n",
       "      <td>-17.909994</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>3362.734136</td>\n",
       "      <td>1220.548073</td>\n",
       "      <td>...</td>\n",
       "      <td>52.656174</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.079857</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>-0.009284</td>\n",
       "      <td>-0.002340</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>2332.780518</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>03-01-07-01-02-01-21.wav</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>disgust</td>\n",
       "      <td>07</td>\n",
       "      <td>1.696</td>\n",
       "      <td>-17.534981</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>2965.614712</td>\n",
       "      <td>1101.992031</td>\n",
       "      <td>...</td>\n",
       "      <td>51.646616</td>\n",
       "      <td>-0.024405</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>-0.067770</td>\n",
       "      <td>-0.032034</td>\n",
       "      <td>-0.011848</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>2187.190674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>03-01-07-01-02-01-21.wav_stretch</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>disgust</td>\n",
       "      <td>07</td>\n",
       "      <td>2.120</td>\n",
       "      <td>-16.670708</td>\n",
       "      <td>0.815094</td>\n",
       "      <td>2993.489932</td>\n",
       "      <td>1055.075245</td>\n",
       "      <td>...</td>\n",
       "      <td>51.237660</td>\n",
       "      <td>-0.024020</td>\n",
       "      <td>0.016230</td>\n",
       "      <td>-0.064485</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>-0.017546</td>\n",
       "      <td>-0.010262</td>\n",
       "      <td>0.184906</td>\n",
       "      <td>2201.601807</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>03-01-07-01-02-01-21.wav_shift</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>disgust</td>\n",
       "      <td>07</td>\n",
       "      <td>1.696</td>\n",
       "      <td>-16.815996</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>3136.969590</td>\n",
       "      <td>1078.761809</td>\n",
       "      <td>...</td>\n",
       "      <td>52.770287</td>\n",
       "      <td>0.012701</td>\n",
       "      <td>0.028132</td>\n",
       "      <td>0.081926</td>\n",
       "      <td>-0.011260</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>-0.006709</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>2286.410889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4320 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename  actor  gender  emotion emotion_code  \\\n",
       "0             03-01-07-01-01-02-18.wav     18    male  disgust           07   \n",
       "1     03-01-07-01-01-02-18.wav_stretch     18    male  disgust           07   \n",
       "2       03-01-07-01-01-02-18.wav_shift     18    male  disgust           07   \n",
       "3             03-01-05-01-02-01-18.wav     18    male    angry           05   \n",
       "4     03-01-05-01-02-01-18.wav_stretch     18    male    angry           05   \n",
       "...                                ...    ...     ...      ...          ...   \n",
       "4315  03-01-07-02-02-02-21.wav_stretch     21  female  disgust           07   \n",
       "4316    03-01-07-02-02-02-21.wav_shift     21  female  disgust           07   \n",
       "4317          03-01-07-01-02-01-21.wav     21  female  disgust           07   \n",
       "4318  03-01-07-01-02-01-21.wav_stretch     21  female  disgust           07   \n",
       "4319    03-01-07-01-02-01-21.wav_shift     21  female  disgust           07   \n",
       "\n",
       "      duration   loudness  voice_ratio  centroid_mean  centroid_std  ...  \\\n",
       "0        2.176 -17.363924     0.764706    3103.861734   1133.595952  ...   \n",
       "1        2.720 -16.133003     0.776471    3117.783534   1044.945930  ...   \n",
       "2        2.176 -16.485405     0.823529    3229.374024   1080.269650  ...   \n",
       "3        1.632 -12.006447     0.980392    3149.329740   1393.901212  ...   \n",
       "4        2.040 -12.320189     0.988235    3173.226784   1353.186854  ...   \n",
       "...        ...        ...          ...            ...           ...  ...   \n",
       "4315     2.440 -17.121801     0.681967    3172.201855   1212.521763  ...   \n",
       "4316     1.952 -17.909994     0.819672    3362.734136   1220.548073  ...   \n",
       "4317     1.696 -17.534981     0.792453    2965.614712   1101.992031  ...   \n",
       "4318     2.120 -16.670708     0.815094    2993.489932   1055.075245  ...   \n",
       "4319     1.696 -16.815996     0.886792    3136.969590   1078.761809  ...   \n",
       "\n",
       "      contrast_7  tonnetz_1  tonnetz_2  tonnetz_3  tonnetz_4  tonnetz_5  \\\n",
       "0      51.832581  -0.018983  -0.025689  -0.019540   0.037315  -0.004874   \n",
       "1      51.422385  -0.005568  -0.029710  -0.014867   0.044577  -0.008606   \n",
       "2      53.300893  -0.029735   0.004281   0.034622  -0.051420   0.008897   \n",
       "3      50.715246  -0.001349  -0.016009   0.012247  -0.020919  -0.010431   \n",
       "4      50.693348   0.019958  -0.022524   0.015145  -0.022695  -0.009523   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "4315   50.792559  -0.010724   0.030826  -0.064574  -0.008770  -0.001116   \n",
       "4316   52.656174   0.015232   0.011795   0.079857   0.013958  -0.009284   \n",
       "4317   51.646616  -0.024405  -0.000358  -0.067770  -0.032034  -0.011848   \n",
       "4318   51.237660  -0.024020   0.016230  -0.064485   0.004123  -0.017546   \n",
       "4319   52.770287   0.012701   0.028132   0.081926  -0.011260   0.009236   \n",
       "\n",
       "      tonnetz_6  silence_ratio   pitch_mean  energy_ratio  \n",
       "0     -0.002966       0.235294  2245.666748           NaN  \n",
       "1     -0.012778       0.223529  2203.087402           NaN  \n",
       "2      0.000196       0.176471  2135.273682           NaN  \n",
       "3     -0.004213            NaN  2139.219238     23.973597  \n",
       "4     -0.004047            NaN  2079.598633     13.721988  \n",
       "...         ...            ...          ...           ...  \n",
       "4315   0.002784       0.318033  2215.400879           NaN  \n",
       "4316  -0.002340       0.180328  2332.780518           NaN  \n",
       "4317   0.000847       0.207547  2187.190674           NaN  \n",
       "4318  -0.010262       0.184906  2201.601807           NaN  \n",
       "4319  -0.006709       0.113208  2286.410889           NaN  \n",
       "\n",
       "[4320 rows x 74 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af04514c-b622-4b46-95e0-10f193a09b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"audio_metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2046d5e-3b25-439c-bd5c-9b216570941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Processed 4320 files.\n",
      "Saved to 'audio_metadata.csv'\n",
      "\n",
      "Sample data:\n",
      "                           filename  actor gender  emotion emotion_code  \\\n",
      "0          03-01-07-01-01-02-18.wav     18   male  disgust           07   \n",
      "1  03-01-07-01-01-02-18.wav_stretch     18   male  disgust           07   \n",
      "2    03-01-07-01-01-02-18.wav_shift     18   male  disgust           07   \n",
      "3          03-01-05-01-02-01-18.wav     18   male    angry           05   \n",
      "4  03-01-05-01-02-01-18.wav_stretch     18   male    angry           05   \n",
      "\n",
      "   duration   loudness  voice_ratio  centroid_mean  centroid_std  ...  \\\n",
      "0     2.176 -17.363924     0.764706    3103.861734   1133.595952  ...   \n",
      "1     2.720 -16.133003     0.776471    3117.783534   1044.945930  ...   \n",
      "2     2.176 -16.485405     0.823529    3229.374024   1080.269650  ...   \n",
      "3     1.632 -12.006447     0.980392    3149.329740   1393.901212  ...   \n",
      "4     2.040 -12.320189     0.988235    3173.226784   1353.186854  ...   \n",
      "\n",
      "   contrast_7  tonnetz_1  tonnetz_2  tonnetz_3  tonnetz_4  tonnetz_5  \\\n",
      "0   51.832581  -0.018983  -0.025689  -0.019540   0.037315  -0.004874   \n",
      "1   51.422385  -0.005568  -0.029710  -0.014867   0.044577  -0.008606   \n",
      "2   53.300893  -0.029735   0.004281   0.034622  -0.051420   0.008897   \n",
      "3   50.715246  -0.001349  -0.016009   0.012247  -0.020919  -0.010431   \n",
      "4   50.693348   0.019958  -0.022524   0.015145  -0.022695  -0.009523   \n",
      "\n",
      "   tonnetz_6  silence_ratio   pitch_mean  energy_ratio  \n",
      "0  -0.002966       0.235294  2245.666748           NaN  \n",
      "1  -0.012778       0.223529  2203.087402           NaN  \n",
      "2   0.000196       0.176471  2135.273682           NaN  \n",
      "3  -0.004213            NaN  2139.219238     23.973597  \n",
      "4  -0.004047            NaN  2079.598633     13.721988  \n",
      "\n",
      "[5 rows x 74 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nDone! Processed {len(df)} files.\")\n",
    "print(\"Saved to 'audio_metadata.csv'\")\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce635a95-1a5e-4d25-9e20-74097520717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of dataset: (4320, 74)\n",
      "\n",
      "Columns: ['filename', 'actor', 'gender', 'emotion', 'emotion_code', 'duration', 'loudness', 'voice_ratio', 'centroid_mean', 'centroid_std', 'centroid_skew', 'centroid_kurt', 'rolloff_mean', 'rolloff_std', 'rolloff_skew', 'rolloff_kurt', 'bandwidth_mean', 'bandwidth_std', 'bandwidth_skew', 'bandwidth_kurt', 'mfcc_1', 'mfcc_1_delta', 'mfcc_2', 'mfcc_2_delta', 'mfcc_3', 'mfcc_3_delta', 'mfcc_4', 'mfcc_4_delta', 'mfcc_5', 'mfcc_5_delta', 'mfcc_6', 'mfcc_6_delta', 'mfcc_7', 'mfcc_7_delta', 'mfcc_8', 'mfcc_8_delta', 'mfcc_9', 'mfcc_9_delta', 'mfcc_10', 'mfcc_10_delta', 'mfcc_11', 'mfcc_11_delta', 'mfcc_12', 'mfcc_12_delta', 'mfcc_13', 'mfcc_13_delta', 'chroma_1', 'chroma_2', 'chroma_3', 'chroma_4', 'chroma_5', 'chroma_6', 'chroma_7', 'chroma_8', 'chroma_9', 'chroma_10', 'chroma_11', 'chroma_12', 'contrast_1', 'contrast_2', 'contrast_3', 'contrast_4', 'contrast_5', 'contrast_6', 'contrast_7', 'tonnetz_1', 'tonnetz_2', 'tonnetz_3', 'tonnetz_4', 'tonnetz_5', 'tonnetz_6', 'silence_ratio', 'pitch_mean', 'energy_ratio']\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\\nShape of dataset:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75ef7284-b12d-40eb-bb6c-9f1260ed63d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emotion classes: ['disgust' 'angry' 'sad' 'calm' 'neutral' 'fearful' 'happy' 'surprised']\n"
     ]
    }
   ],
   "source": [
    "# Check unique emotions\n",
    "print(\"\\nEmotion classes:\", df['emotion'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72b6738d-6b4a-46f0-98a1-50d79c48c17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      " filename            0\n",
      "actor               0\n",
      "gender              0\n",
      "emotion             0\n",
      "emotion_code        0\n",
      "                 ... \n",
      "tonnetz_5           0\n",
      "tonnetz_6           0\n",
      "silence_ratio    2304\n",
      "pitch_mean          0\n",
      "energy_ratio     2016\n",
      "Length: 74, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bdd4b69-436d-4f67-ae90-d6853862b198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics:\n",
      "                        filename        actor gender  emotion emotion_code  \\\n",
      "count                       4320  4320.000000   4320     4320         4320   \n",
      "unique                      4320          NaN      2        8            8   \n",
      "top     03-01-07-01-01-02-18.wav          NaN   male  disgust           07   \n",
      "freq                           1          NaN   2160      576          576   \n",
      "mean                         NaN    12.500000    NaN      NaN          NaN   \n",
      "std                          NaN     6.922988    NaN      NaN          NaN   \n",
      "min                          NaN     1.000000    NaN      NaN          NaN   \n",
      "25%                          NaN     6.750000    NaN      NaN          NaN   \n",
      "50%                          NaN    12.500000    NaN      NaN          NaN   \n",
      "75%                          NaN    18.250000    NaN      NaN          NaN   \n",
      "max                          NaN    24.000000    NaN      NaN          NaN   \n",
      "\n",
      "           duration     loudness  voice_ratio  centroid_mean  centroid_std  \\\n",
      "count   4320.000000  4320.000000  4320.000000    4320.000000   4320.000000   \n",
      "unique          NaN          NaN          NaN            NaN           NaN   \n",
      "top             NaN          NaN          NaN            NaN           NaN   \n",
      "freq            NaN          NaN          NaN            NaN           NaN   \n",
      "mean       1.945654   -14.098446     0.903118    3302.364760   1028.186989   \n",
      "std        0.477625     2.339286     0.107825     286.897233    199.396243   \n",
      "min        0.928000   -26.728384     0.360563    2473.371392    358.819717   \n",
      "25%        1.624000   -14.991534     0.860000    3097.115256    893.582285   \n",
      "50%        1.856000   -13.505986     0.948148    3297.160134   1025.807380   \n",
      "75%        2.176000   -12.545161     0.979167    3489.779394   1158.723941   \n",
      "max        5.389938    -9.608130     1.000000    4544.164645   1690.564096   \n",
      "\n",
      "        ...   contrast_7    tonnetz_1    tonnetz_2    tonnetz_3    tonnetz_4  \\\n",
      "count   ...  4320.000000  4320.000000  4320.000000  4320.000000  4320.000000   \n",
      "unique  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "top     ...          NaN          NaN          NaN          NaN          NaN   \n",
      "freq    ...          NaN          NaN          NaN          NaN          NaN   \n",
      "mean    ...    51.652917    -0.007272     0.006009     0.007474    -0.002234   \n",
      "std     ...     1.675522     0.027421     0.026301     0.040355     0.039393   \n",
      "min     ...    46.566999    -0.147232    -0.114218    -0.182839    -0.164397   \n",
      "25%     ...    50.479908    -0.023303    -0.010342    -0.016793    -0.027166   \n",
      "50%     ...    51.575106    -0.007523     0.005765     0.007613    -0.002458   \n",
      "75%     ...    52.769577     0.009264     0.021513     0.032190     0.022419   \n",
      "max     ...    58.075300     0.113690     0.146009     0.168933     0.166233   \n",
      "\n",
      "          tonnetz_5    tonnetz_6  silence_ratio   pitch_mean  energy_ratio  \n",
      "count   4320.000000  4320.000000    2016.000000  4320.000000   2304.000000  \n",
      "unique          NaN          NaN            NaN          NaN           NaN  \n",
      "top             NaN          NaN            NaN          NaN           NaN  \n",
      "freq            NaN          NaN            NaN          NaN           NaN  \n",
      "mean      -0.000844    -0.001664       0.130417  2155.519043     12.567689  \n",
      "std        0.013298     0.013444       0.126568   158.128082     10.361625  \n",
      "min       -0.060432    -0.052691       0.000000  1521.067993      0.857396  \n",
      "25%       -0.008894    -0.009831       0.032558  2054.048889      6.013583  \n",
      "50%       -0.000540    -0.001603       0.078431  2158.635620      9.649889  \n",
      "75%        0.007525     0.006580       0.200633  2262.800415     15.238182  \n",
      "max        0.050976     0.053031       0.639437  2665.607178    112.253944  \n",
      "\n",
      "[11 rows x 74 columns]\n"
     ]
    }
   ],
   "source": [
    "# Summary stats\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f29d928-37d1-42f1-a419-10d9c033683c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns.to_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
